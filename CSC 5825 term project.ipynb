{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zRbojKvBnCZq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorboard\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "from random import sample, seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xaIkogkm-sO"
      },
      "source": [
        "Data Loading Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZwSXRfu9_CfW"
      },
      "outputs": [],
      "source": [
        "#Data Loading\n",
        "\n",
        "df = pd.read_csv(\"birds.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1yqgYzid6Tj6",
        "outputId": "ebf2d09f-ecc4-4a8d-c7ab-3b4c7ccac2a3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class id</th>\n",
              "      <th>filepaths</th>\n",
              "      <th>labels</th>\n",
              "      <th>data set</th>\n",
              "      <th>scientific name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>train/ABBOTTS BABBLER/001.jpg</td>\n",
              "      <td>ABBOTTS BABBLER</td>\n",
              "      <td>train</td>\n",
              "      <td>MALACOCINCLA ABBOTTI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>train/ABBOTTS BABBLER/002.jpg</td>\n",
              "      <td>ABBOTTS BABBLER</td>\n",
              "      <td>train</td>\n",
              "      <td>MALACOCINCLA ABBOTTI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>train/ABBOTTS BABBLER/003.jpg</td>\n",
              "      <td>ABBOTTS BABBLER</td>\n",
              "      <td>train</td>\n",
              "      <td>MALACOCINCLA ABBOTTI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>train/ABBOTTS BABBLER/004.jpg</td>\n",
              "      <td>ABBOTTS BABBLER</td>\n",
              "      <td>train</td>\n",
              "      <td>MALACOCINCLA ABBOTTI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>train/ABBOTTS BABBLER/005.jpg</td>\n",
              "      <td>ABBOTTS BABBLER</td>\n",
              "      <td>train</td>\n",
              "      <td>MALACOCINCLA ABBOTTI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   class id                      filepaths           labels data set   \n",
              "0         0  train/ABBOTTS BABBLER/001.jpg  ABBOTTS BABBLER    train  \\\n",
              "1         0  train/ABBOTTS BABBLER/002.jpg  ABBOTTS BABBLER    train   \n",
              "2         0  train/ABBOTTS BABBLER/003.jpg  ABBOTTS BABBLER    train   \n",
              "3         0  train/ABBOTTS BABBLER/004.jpg  ABBOTTS BABBLER    train   \n",
              "4         0  train/ABBOTTS BABBLER/005.jpg  ABBOTTS BABBLER    train   \n",
              "\n",
              "        scientific name  \n",
              "0  MALACOCINCLA ABBOTTI  \n",
              "1  MALACOCINCLA ABBOTTI  \n",
              "2  MALACOCINCLA ABBOTTI  \n",
              "3  MALACOCINCLA ABBOTTI  \n",
              "4  MALACOCINCLA ABBOTTI  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DMiO1bNK7lOw"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class id</th>\n",
              "      <th>filepaths</th>\n",
              "      <th>labels</th>\n",
              "      <th>data set</th>\n",
              "      <th>scientific name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>train/ABBOTTS BABBLER/001.jpg</td>\n",
              "      <td>ABBOTTS BABBLER</td>\n",
              "      <td>train</td>\n",
              "      <td>MALACOCINCLA ABBOTTI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>train/ABBOTTS BABBLER/002.jpg</td>\n",
              "      <td>ABBOTTS BABBLER</td>\n",
              "      <td>train</td>\n",
              "      <td>MALACOCINCLA ABBOTTI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>train/ABBOTTS BABBLER/003.jpg</td>\n",
              "      <td>ABBOTTS BABBLER</td>\n",
              "      <td>train</td>\n",
              "      <td>MALACOCINCLA ABBOTTI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>train/ABBOTTS BABBLER/004.jpg</td>\n",
              "      <td>ABBOTTS BABBLER</td>\n",
              "      <td>train</td>\n",
              "      <td>MALACOCINCLA ABBOTTI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>train/ABBOTTS BABBLER/005.jpg</td>\n",
              "      <td>ABBOTTS BABBLER</td>\n",
              "      <td>train</td>\n",
              "      <td>MALACOCINCLA ABBOTTI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82719</th>\n",
              "      <td>514</td>\n",
              "      <td>train/ZEBRA DOVE/95.jpg</td>\n",
              "      <td>ZEBRA DOVE</td>\n",
              "      <td>train</td>\n",
              "      <td>GEOPELIA STRIATA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82720</th>\n",
              "      <td>514</td>\n",
              "      <td>train/ZEBRA DOVE/96.jpg</td>\n",
              "      <td>ZEBRA DOVE</td>\n",
              "      <td>train</td>\n",
              "      <td>GEOPELIA STRIATA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82721</th>\n",
              "      <td>514</td>\n",
              "      <td>train/ZEBRA DOVE/97.jpg</td>\n",
              "      <td>ZEBRA DOVE</td>\n",
              "      <td>train</td>\n",
              "      <td>GEOPELIA STRIATA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82722</th>\n",
              "      <td>514</td>\n",
              "      <td>train/ZEBRA DOVE/98.jpg</td>\n",
              "      <td>ZEBRA DOVE</td>\n",
              "      <td>train</td>\n",
              "      <td>GEOPELIA STRIATA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82723</th>\n",
              "      <td>514</td>\n",
              "      <td>train/ZEBRA DOVE/99.jpg</td>\n",
              "      <td>ZEBRA DOVE</td>\n",
              "      <td>train</td>\n",
              "      <td>GEOPELIA STRIATA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>82724 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       class id                      filepaths           labels data set   \n",
              "0             0  train/ABBOTTS BABBLER/001.jpg  ABBOTTS BABBLER    train  \\\n",
              "1             0  train/ABBOTTS BABBLER/002.jpg  ABBOTTS BABBLER    train   \n",
              "2             0  train/ABBOTTS BABBLER/003.jpg  ABBOTTS BABBLER    train   \n",
              "3             0  train/ABBOTTS BABBLER/004.jpg  ABBOTTS BABBLER    train   \n",
              "4             0  train/ABBOTTS BABBLER/005.jpg  ABBOTTS BABBLER    train   \n",
              "...         ...                            ...              ...      ...   \n",
              "82719       514        train/ZEBRA DOVE/95.jpg       ZEBRA DOVE    train   \n",
              "82720       514        train/ZEBRA DOVE/96.jpg       ZEBRA DOVE    train   \n",
              "82721       514        train/ZEBRA DOVE/97.jpg       ZEBRA DOVE    train   \n",
              "82722       514        train/ZEBRA DOVE/98.jpg       ZEBRA DOVE    train   \n",
              "82723       514        train/ZEBRA DOVE/99.jpg       ZEBRA DOVE    train   \n",
              "\n",
              "            scientific name  \n",
              "0      MALACOCINCLA ABBOTTI  \n",
              "1      MALACOCINCLA ABBOTTI  \n",
              "2      MALACOCINCLA ABBOTTI  \n",
              "3      MALACOCINCLA ABBOTTI  \n",
              "4      MALACOCINCLA ABBOTTI  \n",
              "...                     ...  \n",
              "82719      GEOPELIA STRIATA  \n",
              "82720      GEOPELIA STRIATA  \n",
              "82721      GEOPELIA STRIATA  \n",
              "82722      GEOPELIA STRIATA  \n",
              "82723      GEOPELIA STRIATA  \n",
              "\n",
              "[82724 rows x 5 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#To use the 200 class variant, uncomment the seed and df = df[df[\"class id\"].isin(used_class_ids)] lines to have the datasets contain only 200 classes\n",
        "\n",
        "#seed(123)\n",
        "number_of_clases = 200\n",
        "class_ids = list(df[\"class id\"].unique())\n",
        "used_class_ids = sample(class_ids, 200)\n",
        "#df = df[df[\"class id\"].isin(used_class_ids)]\n",
        "train_df = df[df['data set'] == \"train\"]\n",
        "val_df = df[df['data set'] == \"valid\"]\n",
        "test_df = df[df['data set'] == \"test\"]\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU0N9Rbb5FqR",
        "outputId": "08ebcfd0-2869-4a8b-99a9-8e4d06ea43ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 82724 validated image filenames belonging to 515 classes.\n",
            "Found 2575 validated image filenames belonging to 515 classes.\n",
            "Found 2575 validated image filenames belonging to 515 classes.\n"
          ]
        }
      ],
      "source": [
        "generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n",
        ")\n",
        "\n",
        "batch_size = 256\n",
        "seed = 123\n",
        "target_size = (64,64)\n",
        "\n",
        "train_images = generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=seed,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_images = generator.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=seed,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "test_images = generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 82724 validated image filenames belonging to 515 classes.\n",
            "Found 2575 validated image filenames belonging to 515 classes.\n",
            "Found 2575 validated image filenames belonging to 515 classes.\n"
          ]
        }
      ],
      "source": [
        "generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n",
        ")\n",
        "\n",
        "batch_size = 256\n",
        "seed = 123\n",
        "target_size = (64,64)\n",
        "\n",
        "train_images_rgb = generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=seed,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_images_rgb = generator.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=seed,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "test_images_rgb = generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x22aff224410>"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(train_images.next()[0][0].astype(\"uint8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAT8rUZAoPdS"
      },
      "source": [
        "Model Creation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "200 class 2D CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3), padding = \"same\", strides = (2), activation=\"relu\", input_shape = (64,64, 1)))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(3), padding = \"valid\", strides = (2)))\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3), padding = \"same\", strides = (2), activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(3), padding = \"valid\", strides = (2)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(100, activation = \"relu\"))\n",
        "model.add(tf.keras.layers.Dense(200, activation = \"softmax\"))\n",
        "\n",
        "model.build()\n",
        "\n",
        "optimizer = tf.optimizers.Adam(learning_rate = 0.0001)\n",
        "loss_fn = tf.losses.CategoricalCrossentropy()\n",
        "acc_fn = tf.metrics.CategoricalAccuracy()\n",
        "ckpt_path = \"ckpt/checkpoint/2D_200_class\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path)\n",
        "model.compile(optimizer, loss_fn, metrics = [acc_fn])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "515 class 2D CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3), padding = \"same\", strides = (2), activation=\"relu\", input_shape = (64,64, 1)))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(3), padding = \"valid\", strides = (2)))\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3), padding = \"same\", strides = (2), activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(3), padding = \"valid\", strides = (2)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(100, activation = \"relu\"))\n",
        "model.add(tf.keras.layers.Dense(515, activation = \"softmax\"))\n",
        "\n",
        "model.build()\n",
        "\n",
        "optimizer = tf.optimizers.Adam(learning_rate = 0.0001)\n",
        "loss_fn = tf.losses.CategoricalCrossentropy()\n",
        "acc_fn = tf.metrics.CategoricalAccuracy()\n",
        "ckpt_path = \"ckpt/checkpoint/2D_515_class\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path)\n",
        "model.compile(optimizer, loss_fn, metrics = [acc_fn])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "200 class 3D CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DilPqNpmoPCg"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Reshape((-1, 64, 64, 3), name = \"reshape\", input_shape = (64,64,3)))\n",
        "model.add(tf.keras.layers.Conv3D(filters=32, kernel_size=(3), padding = \"same\", strides = (2), activation=\"relu\", name = \"conv1\"))\n",
        "model.add(tf.keras.layers.MaxPool3D(pool_size=(3), padding = \"same\", strides = (2), name = \"pool1\"))\n",
        "model.add(tf.keras.layers.Conv3D(filters=64, kernel_size=(3), padding = \"same\", strides = (2), activation=\"relu\", name = \"conv2\"))\n",
        "model.add(tf.keras.layers.MaxPool3D(pool_size=(3), padding = \"same\", strides = (2), name = \"pool2\"))\n",
        "model.add(tf.keras.layers.Flatten(name = \"flat\"))\n",
        "model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"dense1\"))\n",
        "model.add(tf.keras.layers.Dense(200, activation = \"softmax\", name = \"dense3\"))\n",
        "\n",
        "model.build()\n",
        "\n",
        "optimizer = tf.optimizers.Adam()\n",
        "loss_fn = tf.losses.CategoricalCrossentropy()\n",
        "acc_fn = tf.metrics.CategoricalAccuracy()\n",
        "ckpt_path = \"ckpt/checkpoint/3D_200_class\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path)\n",
        "model.compile(optimizer, loss_fn, metrics = [acc_fn])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "515 class 3D CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Reshape((-1, 64, 64, 3), name = \"reshape\", input_shape = (64,64,3)))\n",
        "model.add(tf.keras.layers.Conv3D(filters=32, kernel_size=(3), padding = \"same\", strides = (2), activation=\"relu\", name = \"conv1\"))\n",
        "model.add(tf.keras.layers.MaxPool3D(pool_size=(3), padding = \"same\", strides = (2), name = \"pool1\"))\n",
        "model.add(tf.keras.layers.Conv3D(filters=64, kernel_size=(3), padding = \"same\", strides = (2), activation=\"relu\", name = \"conv2\"))\n",
        "model.add(tf.keras.layers.MaxPool3D(pool_size=(3), padding = \"same\", strides = (2), name = \"pool2\"))\n",
        "model.add(tf.keras.layers.Flatten(name = \"flat\"))\n",
        "model.add(tf.keras.layers.Dense(100, activation = \"relu\", name = \"dense1\"))\n",
        "model.add(tf.keras.layers.Dense(515, activation = \"softmax\", name = \"dense3\"))\n",
        "\n",
        "model.build()\n",
        "\n",
        "optimizer = tf.optimizers.Adam()\n",
        "loss_fn = tf.losses.CategoricalCrossentropy()\n",
        "acc_fn = tf.metrics.CategoricalAccuracy()\n",
        "ckpt_path = \"ckpt/checkpoint/3D_515_class\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path)\n",
        "model.compile(optimizer, loss_fn, metrics = [acc_fn])\n",
        "model.build()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 32, 32, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 15, 15, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 8, 8, 64)          18496     \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 3, 3, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               57700     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 200)               20200     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 96,716\n",
            "Trainable params: 96,716\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Webh1IEoJrr"
      },
      "source": [
        "Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet_rs/resnet-rs-101-i192_notop.h5\n",
            "247817848/247817848 [==============================] - 9s 0us/step\n",
            "Model: \"model_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_88 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " resnet-rs-101 (Functional)  (None, 2, 2, 2048)        61675296  \n",
            "                                                                 \n",
            " global_average_pooling2d_8   (None, 2048)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 100)               204900    \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 515)               52015     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 61,932,211\n",
            "Trainable params: 256,915\n",
            "Non-trainable params: 61,675,296\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "mobileNet_base = tf.keras.applications.ResNetRS101(input_shape=(64, 64, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "mobileNet_base.trainable = False\n",
        "\n",
        "ins = tf.keras.Input(shape=(64,64,3))\n",
        "ins = tf.keras.applications.resnet50.preprocess_input(ins)\n",
        "x = mobileNet_base(ins)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(100, activation=\"relu\")(x)\n",
        "predictor_head = tf.keras.layers.Dense(515, activation=\"softmax\")(x)\n",
        "\n",
        "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate = 0.0001)\n",
        "ckpt_path = \"ckpt/checkpoint/ResNet101_transfer_64_64\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path)\n",
        "transfer_model = tf.keras.Model(inputs=ins, outputs = predictor_head)\n",
        "transfer_model.compile(optimizer, loss_fn, metrics = [acc_fn])\n",
        "transfer_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "pD12IENRoMpE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 8.6099 - categorical_accuracy: 0.0052"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 50s 391ms/step - loss: 8.6099 - categorical_accuracy: 0.0052 - val_loss: 5.3100 - val_categorical_accuracy: 0.0080\n",
            "Epoch 2/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 5.3060 - categorical_accuracy: 0.0065"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 46s 365ms/step - loss: 5.3060 - categorical_accuracy: 0.0065 - val_loss: 5.3032 - val_categorical_accuracy: 0.0080\n",
            "Epoch 3/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 5.2996 - categorical_accuracy: 0.0075"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 47s 370ms/step - loss: 5.2996 - categorical_accuracy: 0.0075 - val_loss: 5.3012 - val_categorical_accuracy: 0.0090\n",
            "Epoch 4/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 5.2948 - categorical_accuracy: 0.0101"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 46s 363ms/step - loss: 5.2948 - categorical_accuracy: 0.0101 - val_loss: 5.2986 - val_categorical_accuracy: 0.0100\n",
            "Epoch 5/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 5.2878 - categorical_accuracy: 0.0112"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 44s 345ms/step - loss: 5.2878 - categorical_accuracy: 0.0112 - val_loss: 5.2854 - val_categorical_accuracy: 0.0080\n",
            "Epoch 6/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 5.2717 - categorical_accuracy: 0.0131"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 44s 351ms/step - loss: 5.2717 - categorical_accuracy: 0.0131 - val_loss: 5.2651 - val_categorical_accuracy: 0.0120\n",
            "Epoch 7/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 5.2478 - categorical_accuracy: 0.0148"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 44s 352ms/step - loss: 5.2478 - categorical_accuracy: 0.0148 - val_loss: 5.2459 - val_categorical_accuracy: 0.0150\n",
            "Epoch 8/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 5.2223 - categorical_accuracy: 0.0149"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 46s 365ms/step - loss: 5.2223 - categorical_accuracy: 0.0149 - val_loss: 5.2153 - val_categorical_accuracy: 0.0120\n",
            "Epoch 9/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 5.1930 - categorical_accuracy: 0.0154"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 46s 363ms/step - loss: 5.1930 - categorical_accuracy: 0.0154 - val_loss: 5.1931 - val_categorical_accuracy: 0.0120\n",
            "Epoch 10/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 5.1664 - categorical_accuracy: 0.0154"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 47s 373ms/step - loss: 5.1664 - categorical_accuracy: 0.0154 - val_loss: 5.1674 - val_categorical_accuracy: 0.0140\n",
            "Epoch 11/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 5.1396 - categorical_accuracy: 0.0167"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 46s 362ms/step - loss: 5.1396 - categorical_accuracy: 0.0167 - val_loss: 5.1431 - val_categorical_accuracy: 0.0180\n",
            "Epoch 12/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 5.1163 - categorical_accuracy: 0.0203"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 47s 372ms/step - loss: 5.1163 - categorical_accuracy: 0.0203 - val_loss: 5.1170 - val_categorical_accuracy: 0.0160\n",
            "Epoch 13/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 5.0896 - categorical_accuracy: 0.0224"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 47s 373ms/step - loss: 5.0896 - categorical_accuracy: 0.0224 - val_loss: 5.1025 - val_categorical_accuracy: 0.0170\n",
            "Epoch 14/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 5.0672 - categorical_accuracy: 0.0233"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 46s 362ms/step - loss: 5.0672 - categorical_accuracy: 0.0233 - val_loss: 5.0783 - val_categorical_accuracy: 0.0220\n",
            "Epoch 15/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 5.0393 - categorical_accuracy: 0.0256"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 43s 340ms/step - loss: 5.0393 - categorical_accuracy: 0.0256 - val_loss: 5.0524 - val_categorical_accuracy: 0.0190\n",
            "Epoch 16/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 5.0134 - categorical_accuracy: 0.0275"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 44s 352ms/step - loss: 5.0134 - categorical_accuracy: 0.0275 - val_loss: 5.0319 - val_categorical_accuracy: 0.0200\n",
            "Epoch 17/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 4.9848 - categorical_accuracy: 0.0292"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 46s 362ms/step - loss: 4.9848 - categorical_accuracy: 0.0292 - val_loss: 5.0029 - val_categorical_accuracy: 0.0260\n",
            "Epoch 18/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 4.9565 - categorical_accuracy: 0.0323"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 46s 361ms/step - loss: 4.9565 - categorical_accuracy: 0.0323 - val_loss: 4.9918 - val_categorical_accuracy: 0.0230\n",
            "Epoch 19/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 4.9227 - categorical_accuracy: 0.0369"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 47s 373ms/step - loss: 4.9227 - categorical_accuracy: 0.0369 - val_loss: 4.9657 - val_categorical_accuracy: 0.0260\n",
            "Epoch 20/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 4.8851 - categorical_accuracy: 0.0425"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 47s 372ms/step - loss: 4.8851 - categorical_accuracy: 0.0425 - val_loss: 4.9192 - val_categorical_accuracy: 0.0390\n",
            "Epoch 21/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 4.8446 - categorical_accuracy: 0.0460"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 46s 363ms/step - loss: 4.8446 - categorical_accuracy: 0.0460 - val_loss: 4.8649 - val_categorical_accuracy: 0.0380\n",
            "Epoch 22/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 4.8027 - categorical_accuracy: 0.0494"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 45s 357ms/step - loss: 4.8027 - categorical_accuracy: 0.0494 - val_loss: 4.8543 - val_categorical_accuracy: 0.0390\n",
            "Epoch 23/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 4.7507 - categorical_accuracy: 0.0523"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 45s 355ms/step - loss: 4.7507 - categorical_accuracy: 0.0523 - val_loss: 4.7950 - val_categorical_accuracy: 0.0450\n",
            "Epoch 24/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 4.7029 - categorical_accuracy: 0.0555"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 45s 355ms/step - loss: 4.7029 - categorical_accuracy: 0.0555 - val_loss: 4.7695 - val_categorical_accuracy: 0.0430\n",
            "Epoch 25/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 4.6511 - categorical_accuracy: 0.0600"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 45s 360ms/step - loss: 4.6511 - categorical_accuracy: 0.0600 - val_loss: 4.7053 - val_categorical_accuracy: 0.0480\n",
            "Epoch 26/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 4.6000 - categorical_accuracy: 0.0637"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 44s 351ms/step - loss: 4.6000 - categorical_accuracy: 0.0637 - val_loss: 4.6529 - val_categorical_accuracy: 0.0510\n",
            "Epoch 27/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 4.5463 - categorical_accuracy: 0.0696"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 43s 343ms/step - loss: 4.5463 - categorical_accuracy: 0.0696 - val_loss: 4.6022 - val_categorical_accuracy: 0.0520\n",
            "Epoch 28/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 4.4938 - categorical_accuracy: 0.0753"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 46s 366ms/step - loss: 4.4938 - categorical_accuracy: 0.0753 - val_loss: 4.5700 - val_categorical_accuracy: 0.0630\n",
            "Epoch 29/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 4.4452 - categorical_accuracy: 0.0815"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 47s 374ms/step - loss: 4.4452 - categorical_accuracy: 0.0815 - val_loss: 4.5315 - val_categorical_accuracy: 0.0680\n",
            "Epoch 30/30\n",
            "126/126 [==============================] - ETA: 0s - loss: 4.3960 - categorical_accuracy: 0.0862"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 48s 376ms/step - loss: 4.3960 - categorical_accuracy: 0.0862 - val_loss: 4.5077 - val_categorical_accuracy: 0.0650\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x14de2dd5ed0>"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Train the models\n",
        "\n",
        "model.fit(train_images, epochs=30, validation_data= val_images, callbacks=[checkpoint])\n",
        "#augmentedDataModel.fit(x=x_train_aug, y=y_train_aug, batch_size=512, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pc0eHFFpMWr"
      },
      "source": [
        "Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "SlGesuGepN8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 338ms/step - loss: 4.4873 - categorical_accuracy: 0.0810\n",
            "4/4 [==============================] - 1s 325ms/step - loss: 4.4873 - categorical_accuracy: 0.0810\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[4.487293720245361, 0.08100000023841858]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss, acc = model.evaluate(test_images)\n",
        "model.evaluate(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Models/2D_200_class\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Models/2D_200_class\\assets\n"
          ]
        }
      ],
      "source": [
        "model.save(\"Models/2D_200_class\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOCxIE5Yt6Za"
      },
      "source": [
        "Show the model Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_model = tf.keras.models.load_model(\"Models/3D_515_class\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 1, 64, 64, 3)      0         \n",
            "                                                                 \n",
            " conv1 (Conv3D)              (None, 1, 32, 32, 32)     2624      \n",
            "                                                                 \n",
            " pool1 (MaxPooling3D)        (None, 1, 16, 16, 32)     0         \n",
            "                                                                 \n",
            " conv2 (Conv3D)              (None, 1, 8, 8, 64)       55360     \n",
            "                                                                 \n",
            " pool2 (MaxPooling3D)        (None, 1, 4, 4, 64)       0         \n",
            "                                                                 \n",
            " flat (Flatten)              (None, 1024)              0         \n",
            "                                                                 \n",
            " dense1 (Dense)              (None, 100)               102500    \n",
            "                                                                 \n",
            " dense3 (Dense)              (None, 515)               52015     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212,499\n",
            "Trainable params: 212,499\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "loaded_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "324/324 [==============================] - 114s 349ms/step - loss: 2.1496 - categorical_accuracy: 0.4915\n",
            "11/11 [==============================] - 4s 323ms/step - loss: 2.5273 - categorical_accuracy: 0.4369\n",
            "11/11 [==============================] - 4s 326ms/step - loss: 2.3404 - categorical_accuracy: 0.4649\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.3404181003570557, 0.46485435962677]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loaded_model.evaluate(train_images_rgb)\n",
        "loaded_model.evaluate(val_images_rgb)\n",
        "loaded_model.evaluate(test_images_rgb)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Self transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_input (InputLayer)  [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 64, 64, 3)      0         \n",
            "                                                                 \n",
            " conv1 (Conv3D)              (None, 1, 32, 32, 32)     2624      \n",
            "                                                                 \n",
            " pool1 (MaxPooling3D)        (None, 1, 16, 16, 32)     0         \n",
            "                                                                 \n",
            " conv2 (Conv3D)              (None, 1, 8, 8, 64)       55360     \n",
            "                                                                 \n",
            " pool2 (MaxPooling3D)        (None, 1, 4, 4, 64)       0         \n",
            "                                                                 \n",
            " flat (Flatten)              (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 100)               102500    \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 515)               52015     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212,499\n",
            "Trainable params: 154,515\n",
            "Non-trainable params: 57,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model = tf.keras.models.load_model(\"Models/3D_200_class\")\n",
        "base_model.trainable = False\n",
        "x = base_model.layers[-3].output\n",
        "\n",
        "x = tf.keras.layers.Dense(100, activation=\"relu\")(x)\n",
        "predictor_head = tf.keras.layers.Dense(515, activation=\"softmax\")(x)\n",
        "\n",
        "ckpt_path = \"ckpt/checkpoint/3D_515_class_transfer\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path)\n",
        "transfer_model = tf.keras.Model(inputs=base_model.input, outputs = predictor_head)\n",
        "optimizer = tf.optimizers.Adam(learning_rate = 0.0001)\n",
        "loss_fn = tf.losses.CategoricalCrossentropy()\n",
        "acc_fn = tf.metrics.CategoricalAccuracy()\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path)\n",
        "transfer_model.compile(optimizer, loss_fn, metrics = [acc_fn])\n",
        "transfer_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "324/324 [==============================] - ETA: 0s - loss: 6.0494 - categorical_accuracy: 0.0315"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 173). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "324/324 [==============================] - 556s 2s/step - loss: 6.0494 - categorical_accuracy: 0.0315 - val_loss: 5.6783 - val_categorical_accuracy: 0.0761\n",
            "Epoch 2/10\n",
            "324/324 [==============================] - ETA: 0s - loss: 5.0892 - categorical_accuracy: 0.1521"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 173). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "324/324 [==============================] - 538s 2s/step - loss: 5.0892 - categorical_accuracy: 0.1521 - val_loss: 4.4702 - val_categorical_accuracy: 0.2400\n",
            "Epoch 3/10\n",
            "324/324 [==============================] - ETA: 0s - loss: 4.0082 - categorical_accuracy: 0.3008"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 173). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "324/324 [==============================] - 579s 2s/step - loss: 4.0082 - categorical_accuracy: 0.3008 - val_loss: 3.5463 - val_categorical_accuracy: 0.3650\n",
            "Epoch 4/10\n",
            "324/324 [==============================] - ETA: 0s - loss: 3.2879 - categorical_accuracy: 0.3949"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 173). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "324/324 [==============================] - 568s 2s/step - loss: 3.2879 - categorical_accuracy: 0.3949 - val_loss: 2.9500 - val_categorical_accuracy: 0.4416\n",
            "Epoch 5/10\n",
            "324/324 [==============================] - ETA: 0s - loss: 2.8249 - categorical_accuracy: 0.4564"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 173). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "324/324 [==============================] - 545s 2s/step - loss: 2.8249 - categorical_accuracy: 0.4564 - val_loss: 2.5578 - val_categorical_accuracy: 0.4948\n",
            "Epoch 6/10\n",
            "324/324 [==============================] - ETA: 0s - loss: 2.5097 - categorical_accuracy: 0.4982"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 173). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "324/324 [==============================] - 539s 2s/step - loss: 2.5097 - categorical_accuracy: 0.4982 - val_loss: 2.2775 - val_categorical_accuracy: 0.5390\n",
            "Epoch 7/10\n",
            "324/324 [==============================] - ETA: 0s - loss: 2.2823 - categorical_accuracy: 0.5315"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 173). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "324/324 [==============================] - 586s 2s/step - loss: 2.2823 - categorical_accuracy: 0.5315 - val_loss: 2.0738 - val_categorical_accuracy: 0.5662\n",
            "Epoch 8/10\n",
            "324/324 [==============================] - ETA: 0s - loss: 2.1104 - categorical_accuracy: 0.5567"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 173). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "324/324 [==============================] - 552s 2s/step - loss: 2.1104 - categorical_accuracy: 0.5567 - val_loss: 1.9192 - val_categorical_accuracy: 0.5864\n",
            "Epoch 9/10\n",
            "324/324 [==============================] - ETA: 0s - loss: 1.9746 - categorical_accuracy: 0.5786"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 173). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "324/324 [==============================] - 534s 2s/step - loss: 1.9746 - categorical_accuracy: 0.5786 - val_loss: 1.7950 - val_categorical_accuracy: 0.6148\n",
            "Epoch 10/10\n",
            "324/324 [==============================] - ETA: 0s - loss: 1.8636 - categorical_accuracy: 0.5968"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 173). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ckpt/checkpoint\\ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "324/324 [==============================] - 564s 2s/step - loss: 1.8636 - categorical_accuracy: 0.5968 - val_loss: 1.7008 - val_categorical_accuracy: 0.6330\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1503b143fd0>"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transfer_model.fit(train_images_rgb, epochs=10, validation_data= val_images_rgb, callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 17s 1s/step - loss: 1.6337 - categorical_accuracy: 0.6357\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.633689522743225, 0.6357281804084778]"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transfer_model.evaluate(test_images_rgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 173). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Models/ResNet101_transfer_64_64\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Models/ResNet101_transfer_64_64\\assets\n"
          ]
        }
      ],
      "source": [
        "transfer_model.save(\"Models/ResNet101_transfer_64_64\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transformer Section\n",
        "Model architecture from https://keras.io/examples/vision/image_classification_with_vision_transformer/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_shape = (64,64,3)\n",
        "num_classes = 515\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 256\n",
        "num_epochs = 5\n",
        "image_size = 64 \n",
        "patch_size = 4 \n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 2\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "] \n",
        "transformer_layers = 2\n",
        "mlp_head_units = [50, 100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = tf.keras.layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "class Patches(tf.keras.layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 64, 3)\n"
          ]
        }
      ],
      "source": [
        "print(train_images_rgb.next()[0][0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image size: 64 X 64\n",
            "Patch size: 4 X 4\n",
            "Patches per image: 256\n",
            "Elements per patch: 48\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 256 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(4, 4))\n",
        "image = train_images_rgb.next()[0][0]\n",
        "plt.imshow(image.astype(\"uint8\"))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "resized_image = tf.image.resize(\n",
        "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
        ")\n",
        "patches = Patches(patch_size)(resized_image)\n",
        "print(f\"Image size: {image_size} X {image_size}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
        "print(f\"Patches per image: {patches.shape[1]}\")\n",
        "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
        "\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
        "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Do not perform augmentation to be consistent with the CNN model above\n",
        "\n",
        "data_augmentation = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Normalization(),\n",
        "        tf.keras.layers.Resizing(image_size, image_size)\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PatchEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super().__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = tf.keras.layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = tf.keras.layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "def create_vit_classifier():\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    augmented = data_augmentation(inputs)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(augmented)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = tf.keras.layers.Add()([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = tf.keras.layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = tf.keras.layers.Flatten()(representation)\n",
        "    representation = tf.keras.layers.Dropout(0.5)(representation)\n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    # Classify outputs.\n",
        "    logits = tf.keras.layers.Dense(num_classes)(features)\n",
        "    # Create the Keras model.\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=logits)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "324/324 [==============================] - 1040s 3s/step - loss: 6.2502 - accuracy: 0.0028 - top-5-accuracy: 0.0131 - val_loss: 6.2447 - val_accuracy: 0.0019 - val_top-5-accuracy: 0.0097\n",
            "Epoch 2/5\n",
            "324/324 [==============================] - 1027s 3s/step - loss: 6.2405 - accuracy: 0.0032 - top-5-accuracy: 0.0135 - val_loss: 6.2465 - val_accuracy: 0.0019 - val_top-5-accuracy: 0.0097\n",
            "Epoch 3/5\n",
            "324/324 [==============================] - 1094s 3s/step - loss: 6.2389 - accuracy: 0.0031 - top-5-accuracy: 0.0141 - val_loss: 6.2484 - val_accuracy: 0.0019 - val_top-5-accuracy: 0.0097\n",
            "Epoch 4/5\n",
            "324/324 [==============================] - 1064s 3s/step - loss: 6.2384 - accuracy: 0.0032 - top-5-accuracy: 0.0145 - val_loss: 6.2491 - val_accuracy: 0.0019 - val_top-5-accuracy: 0.0097\n",
            "Epoch 5/5\n",
            "324/324 [==============================] - 1033s 3s/step - loss: 6.2380 - accuracy: 0.0032 - top-5-accuracy: 0.0140 - val_loss: 6.2503 - val_accuracy: 0.0019 - val_top-5-accuracy: 0.0097\n",
            "11/11 [==============================] - 16s 1s/step - loss: 6.2503 - accuracy: 0.0019 - top-5-accuracy: 0.0097\n",
            "Test accuracy: 0.19%\n",
            "Test top 5 accuracy: 0.97%\n"
          ]
        }
      ],
      "source": [
        "def run_experiment(model):\n",
        "    optimizer = tf.optimizers.Adam(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
        "            tf.keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
        "\n",
        "    history = model.fit(\n",
        "        train_images_rgb,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=val_images_rgb\n",
        "    )\n",
        "\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(test_images_rgb)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "vit_classifier = create_vit_classifier()\n",
        "history = run_experiment(vit_classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_addons as tfa\n",
        "from vit_keras import vit, utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\anekl\\Documents\\Python Files\\College\\CSC 7760\\.venv\\Lib\\site-packages\\vit_keras\\utils.py:81: UserWarning: Resizing position embeddings from 12, 12 to 2, 2\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "vit_model = vit.vit_b32(\n",
        "        image_size = (64,64),\n",
        "        activation = 'softmax',\n",
        "        pretrained = True,\n",
        "        include_top = False,\n",
        "        pretrained_top = False,\n",
        "        classes = 515)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vision_transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vit-b32 (Functional)        (None, 768)               87420672  \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 768)               0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 768)              3072      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_176 (Dense)           (None, 100)               76900     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 100)              400       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_177 (Dense)           (None, 515)               52015     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,553,059\n",
            "Trainable params: 130,651\n",
            "Non-trainable params: 87,422,408\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vit_model.trainable = False\n",
        "model = tf.keras.Sequential([\n",
        "        vit_model,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(100, activation = tfa.activations.gelu),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(515, 'softmax')\n",
        "    ],\n",
        "    name = 'vision_transformer')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "324/324 [==============================] - 495s 1s/step - loss: 5.9343 - accuracy: 0.0184 - top-5-accuracy: 0.0621 - val_loss: 5.5055 - val_accuracy: 0.0482 - val_top-5-accuracy: 0.1278\n",
            "Epoch 2/5\n",
            "324/324 [==============================] - 466s 1s/step - loss: 5.3971 - accuracy: 0.0564 - top-5-accuracy: 0.1527 - val_loss: 5.1663 - val_accuracy: 0.0753 - val_top-5-accuracy: 0.1891\n",
            "Epoch 3/5\n",
            "324/324 [==============================] - 459s 1s/step - loss: 5.1253 - accuracy: 0.0821 - top-5-accuracy: 0.2040 - val_loss: 4.9884 - val_accuracy: 0.0955 - val_top-5-accuracy: 0.2283\n",
            "Epoch 4/5\n",
            "324/324 [==============================] - 461s 1s/step - loss: 4.9621 - accuracy: 0.0984 - top-5-accuracy: 0.2332 - val_loss: 4.9073 - val_accuracy: 0.1049 - val_top-5-accuracy: 0.2505\n",
            "Epoch 5/5\n",
            "324/324 [==============================] - 459s 1s/step - loss: 4.8431 - accuracy: 0.1102 - top-5-accuracy: 0.2545 - val_loss: 4.8538 - val_accuracy: 0.1122 - val_top-5-accuracy: 0.2559\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x22afdb12090>"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(\n",
        "        optimizer=tf.optimizers.legacy.Adam(),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=[\n",
        "            tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
        "            tf.keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "model.fit(train_images_rgb, validation_data=val_images_rgb, epochs = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 16s 1s/step - loss: 4.7343 - accuracy: 0.1200 - top-5-accuracy: 0.2738\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[4.73431396484375, 0.11999999731779099, 0.27378639578819275]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_images_rgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " data_augmentation (Sequential)  (None, 64, 64, 3)   7           ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " patches_9 (Patches)            (None, None, 48)     0           ['data_augmentation[0][0]']      \n",
            "                                                                                                  \n",
            " patch_encoder_6 (PatchEncoder)  (None, 256, 64)     19520       ['patches_9[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_102 (Layer  (None, 256, 64)     128         ['patch_encoder_6[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_48 (Multi  (None, 256, 64)     66368       ['layer_normalization_102[0][0]',\n",
            " HeadAttention)                                                   'layer_normalization_102[0][0]']\n",
            "                                                                                                  \n",
            " add_96 (Add)                   (None, 256, 64)      0           ['multi_head_attention_48[0][0]',\n",
            "                                                                  'patch_encoder_6[0][0]']        \n",
            "                                                                                                  \n",
            " layer_normalization_103 (Layer  (None, 256, 64)     128         ['add_96[0][0]']                 \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_121 (Dense)              (None, 256, 128)     8320        ['layer_normalization_103[0][0]']\n",
            "                                                                                                  \n",
            " dropout_114 (Dropout)          (None, 256, 128)     0           ['dense_121[0][0]']              \n",
            "                                                                                                  \n",
            " dense_122 (Dense)              (None, 256, 64)      8256        ['dropout_114[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_115 (Dropout)          (None, 256, 64)      0           ['dense_122[0][0]']              \n",
            "                                                                                                  \n",
            " add_97 (Add)                   (None, 256, 64)      0           ['dropout_115[0][0]',            \n",
            "                                                                  'add_96[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_104 (Layer  (None, 256, 64)     128         ['add_97[0][0]']                 \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_49 (Multi  (None, 256, 64)     66368       ['layer_normalization_104[0][0]',\n",
            " HeadAttention)                                                   'layer_normalization_104[0][0]']\n",
            "                                                                                                  \n",
            " add_98 (Add)                   (None, 256, 64)      0           ['multi_head_attention_49[0][0]',\n",
            "                                                                  'add_97[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_105 (Layer  (None, 256, 64)     128         ['add_98[0][0]']                 \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_123 (Dense)              (None, 256, 128)     8320        ['layer_normalization_105[0][0]']\n",
            "                                                                                                  \n",
            " dropout_116 (Dropout)          (None, 256, 128)     0           ['dense_123[0][0]']              \n",
            "                                                                                                  \n",
            " dense_124 (Dense)              (None, 256, 64)      8256        ['dropout_116[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_117 (Dropout)          (None, 256, 64)      0           ['dense_124[0][0]']              \n",
            "                                                                                                  \n",
            " add_99 (Add)                   (None, 256, 64)      0           ['dropout_117[0][0]',            \n",
            "                                                                  'add_98[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_106 (Layer  (None, 256, 64)     128         ['add_99[0][0]']                 \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_50 (Multi  (None, 256, 64)     66368       ['layer_normalization_106[0][0]',\n",
            " HeadAttention)                                                   'layer_normalization_106[0][0]']\n",
            "                                                                                                  \n",
            " add_100 (Add)                  (None, 256, 64)      0           ['multi_head_attention_50[0][0]',\n",
            "                                                                  'add_99[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_107 (Layer  (None, 256, 64)     128         ['add_100[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_125 (Dense)              (None, 256, 128)     8320        ['layer_normalization_107[0][0]']\n",
            "                                                                                                  \n",
            " dropout_118 (Dropout)          (None, 256, 128)     0           ['dense_125[0][0]']              \n",
            "                                                                                                  \n",
            " dense_126 (Dense)              (None, 256, 64)      8256        ['dropout_118[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_119 (Dropout)          (None, 256, 64)      0           ['dense_126[0][0]']              \n",
            "                                                                                                  \n",
            " add_101 (Add)                  (None, 256, 64)      0           ['dropout_119[0][0]',            \n",
            "                                                                  'add_100[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_108 (Layer  (None, 256, 64)     128         ['add_101[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_51 (Multi  (None, 256, 64)     66368       ['layer_normalization_108[0][0]',\n",
            " HeadAttention)                                                   'layer_normalization_108[0][0]']\n",
            "                                                                                                  \n",
            " add_102 (Add)                  (None, 256, 64)      0           ['multi_head_attention_51[0][0]',\n",
            "                                                                  'add_101[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_109 (Layer  (None, 256, 64)     128         ['add_102[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_127 (Dense)              (None, 256, 128)     8320        ['layer_normalization_109[0][0]']\n",
            "                                                                                                  \n",
            " dropout_120 (Dropout)          (None, 256, 128)     0           ['dense_127[0][0]']              \n",
            "                                                                                                  \n",
            " dense_128 (Dense)              (None, 256, 64)      8256        ['dropout_120[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_121 (Dropout)          (None, 256, 64)      0           ['dense_128[0][0]']              \n",
            "                                                                                                  \n",
            " add_103 (Add)                  (None, 256, 64)      0           ['dropout_121[0][0]',            \n",
            "                                                                  'add_102[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_110 (Layer  (None, 256, 64)     128         ['add_103[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " flatten_6 (Flatten)            (None, 16384)        0           ['layer_normalization_110[0][0]']\n",
            "                                                                                                  \n",
            " dropout_122 (Dropout)          (None, 16384)        0           ['flatten_6[0][0]']              \n",
            "                                                                                                  \n",
            " dense_129 (Dense)              (None, 100)          1638500     ['dropout_122[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_123 (Dropout)          (None, 100)          0           ['dense_129[0][0]']              \n",
            "                                                                                                  \n",
            " dense_130 (Dense)              (None, 100)          10100       ['dropout_123[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_124 (Dropout)          (None, 100)          0           ['dense_130[0][0]']              \n",
            "                                                                                                  \n",
            " dense_131 (Dense)              (None, 515)          52015       ['dropout_124[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,053,070\n",
            "Trainable params: 2,053,063\n",
            "Non-trainable params: 7\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vit_classifier.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, dense_160_layer_call_fn, dense_160_layer_call_and_return_conditional_losses, embedding_10_layer_call_fn, embedding_10_layer_call_and_return_conditional_losses while saving (showing 5 of 29). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Models/ViT_64_64\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Models/ViT_64_64\\assets\n"
          ]
        }
      ],
      "source": [
        "vit_classifier.save(\"Models/ViT_64_64\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) vit-b32_input with unsupported characters which will be renamed to vit_b32_input in the SavedModel.\n",
            "WARNING:absl:`vit-b32_input` is not a valid tf.function parameter name. Sanitizing to `vit_b32_input`.\n",
            "WARNING:absl:`vit-b32_input` is not a valid tf.function parameter name. Sanitizing to `vit_b32_input`.\n",
            "WARNING:absl:`vit-b32_input` is not a valid tf.function parameter name. Sanitizing to `vit_b32_input`.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, MultiHeadDotProductAttention_1_layer_call_fn, MultiHeadDotProductAttention_1_layer_call_and_return_conditional_losses, LayerNorm_0_layer_call_fn, LayerNorm_0_layer_call_and_return_conditional_losses while saving (showing 5 of 193). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Models/ViT_B32_Transfer\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Models/ViT_B32_Transfer\\assets\n"
          ]
        }
      ],
      "source": [
        "model.save(\"Models/ViT_B32_Transfer\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "9dc1d70836e5a95e3204c03be21c6813859f635fe71550fdedfb37e988ddfb3d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
